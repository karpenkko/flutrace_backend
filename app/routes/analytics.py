from sqlalchemy import select, func, cast, String, text
from sqlalchemy.ext.asyncio import AsyncSession
from datetime import datetime, timedelta
from fastapi import APIRouter, Depends, Query
from app.models import Log  
from app.schemas import DashboardOut, TimePoint, FullAnalyticsOut, OSStat, DeviceStat, MessageStat, CountryStat
from app.deps import get_db
from typing import List

router = APIRouter()

@router.get("/projects/{project_token}/dashboard", response_model=DashboardOut)
async def get_dashboard(project_token: str, db: AsyncSession = Depends(get_db)):
    now = datetime.utcnow()
    today_start = now.replace(hour=0, minute=0, second=0, microsecond=0)
    yesterday_start = today_start - timedelta(days=1)
    week_ago_start = today_start - timedelta(days=7)

    # –ó–∞–≥–∞–ª—å–Ω–∞ –∫—ñ–ª—å–∫—ñ—Å—Ç—å –ª–æ–≥—ñ–≤ –∑–∞ —Å—å–æ–≥–æ–¥–Ω—ñ
    total_today_query = select(func.count()).where(
        Log.token == project_token,
        Log.timestamp >= today_start
    )

    # –ö—ñ–ª—å–∫—ñ—Å—Ç—å error —Ç–∞ critical
    error_critical_query = select(
        func.count().filter(Log.level == 'error').label("error"),
        func.count().filter(Log.level == 'critical').label("critical")
    ).where(
        Log.token == project_token,
        Log.timestamp >= today_start
    )

    # –ó–∞–≥–∞–ª—å–Ω–∞ –∫—ñ–ª—å–∫—ñ—Å—Ç—å –≤—á–æ—Ä–∞ —ñ —Ç–∏–∂–¥–µ–Ω—å —Ç–æ–º—É
    total_yesterday_query = select(func.count()).where(
        Log.token == project_token,
        Log.timestamp >= yesterday_start,
        Log.timestamp < today_start
    )

    total_week_ago_query = select(func.count()).where(
        Log.token == project_token,
        Log.timestamp >= week_ago_start,
        Log.timestamp < today_start
    )

    # üìä –î–∏–Ω–∞–º—ñ–∫–∞ –ª–æ–≥—ñ–≤ –∑–∞ –æ—Å—Ç–∞–Ω–Ω—ñ 7 –¥–Ω—ñ–≤
    log_counts_query = select(
        func.date_trunc("day", Log.timestamp).label("date"),
        func.count().label("count")
    ).where(
        Log.token == project_token,
        Log.timestamp >= week_ago_start
    ).group_by(
        text("date")
    ).order_by(text("date"))

    # üìà –†–æ–∑–ø–æ–¥—ñ–ª —Ä—ñ–≤–Ω—ñ–≤ –ª–æ–≥—ñ–≤ –∑–∞ —Å—å–æ–≥–æ–¥–Ω—ñ
    level_distribution_query = select(
        Log.level,
        func.count().label("count")
    ).where(
        Log.token == project_token,
        Log.timestamp >= today_start
    ).group_by(Log.level)

    # üî¢ –ì—Ä—É–ø—É–≤–∞–Ω–Ω—è –∑–∞ –≤–µ—Ä—Å—ñ—î—é
    app_version_expr = cast(Log.custom["appVersion"], String).label("version")

    top_versions_query = select(
        app_version_expr,
        func.count().label("errors")
    ).where(
        Log.token == project_token,
        Log.level.in_(["error", "critical"])
    ).group_by(
        app_version_expr
    ).order_by(
        func.count().desc()
    ).limit(5)

    # üïí –ß–∞—Å –æ—Å—Ç–∞–Ω–Ω—å–æ–≥–æ –ª–æ–≥—É
    last_log_query = select(func.max(Log.timestamp)).where(
        Log.token == project_token
    )

    # üîÑ –í–∏–∫–æ–Ω–∞–Ω–Ω—è –≤—Å—ñ—Ö –∑–∞–ø–∏—Ç—ñ–≤
    total_today = (await db.execute(total_today_query)).scalar()
    error_critical = (await db.execute(error_critical_query)).first()
    total_yesterday = (await db.execute(total_yesterday_query)).scalar()
    total_week_ago = (await db.execute(total_week_ago_query)).scalar()
    log_counts_result = (await db.execute(log_counts_query)).all()
    level_distribution_result = (await db.execute(level_distribution_query)).all()
    top_versions_result = (await db.execute(top_versions_query)).all()
    last_log = (await db.execute(last_log_query)).scalar()

    def get_percentage_change(current, past):
        if past == 0:
            return None
        return round(((current - past) / past) * 100, 2)

    return {
        "total_logs_today": total_today,
        "error_logs_today": error_critical.error,
        "critical_logs_today": error_critical.critical,
        "comparison": {
            "yesterday": get_percentage_change(total_today, total_yesterday),
            "last_week": get_percentage_change(total_today, total_week_ago),
        },
        "log_counts": [
            {"date": row.date.date().isoformat(), "count": row.count}
            for row in log_counts_result
        ],
        "level_distribution_today": [
            {"level": row.level, "count": row.count}
            for row in level_distribution_result
        ],
        "top_versions": [
            {"version": row.version, "errors": row.errors}
            for row in top_versions_result
        ],
        "last_log_timestamp": last_log,
    }

@router.get("/analytics/logs_count", response_model=List[TimePoint])
async def get_logs_count(
    project_token: str,
    interval: str = Query("day", enum=["hour", "day", "month"]),
    db: AsyncSession = Depends(get_db),
):
    now = datetime.utcnow()

    if interval == "hour":
        group_expr = func.date_trunc("hour", Log.timestamp)
        label_format = "HH24:MI"
        start_time = now - timedelta(hours=24)

    elif interval == "day":
        group_expr = func.date_trunc("day", Log.timestamp)
        label_format = "DD.MM"
        start_time = now - timedelta(days=7)

    elif interval == "month":
        group_expr = func.date_trunc("day", Log.timestamp)
        label_format = "DD.MM"
        start_time = now - timedelta(days=30)

    else:
        raise ValueError("Invalid interval")

    query = (
        select(
            func.to_char(group_expr, label_format).label("label"),
            func.count().label("count"),
            group_expr.label("timestamp")
        )
        .where(
            Log.token == project_token,
            Log.timestamp >= start_time
        )
        .group_by(group_expr)
        .order_by(group_expr)
    )

    result = await db.execute(query)
    rows = result.all()

    return [TimePoint(label=row.label, count=row.count, timestamp=row.timestamp) for row in rows]


@router.get("/analytics/summary", response_model=FullAnalyticsOut)
async def get_full_analytics(project_token: str, db: AsyncSession = Depends(get_db)):
    # 1. –û–°
    os_expr = cast(Log.device["platform"], String)
    os_query = (
        select(os_expr.label("os"), func.count().label("count"))
        .where(
            Log.token == project_token,
            os_expr.isnot(None),
            os_expr != ""
        )
        .group_by("os")
    )

    # 2. –ü—Ä–∏—Å—Ç—Ä–æ—ó
    model_expr = cast(Log.device["model"], String)
    model_query = (
        select(model_expr.label("model"), func.count().label("count"))
        .where(
            Log.token == project_token,
            model_expr.isnot(None),
            model_expr != ""
        )
        .group_by("model")
        .order_by(func.count().desc())
        .limit(7)
    )

    # 3. –ü–æ–≤—ñ–¥–æ–º–ª–µ–Ω–Ω—è
    message_query = (
        select(Log.message.label("message"), func.count().label("count"))
        .where(
            Log.token == project_token,
            Log.message.isnot(None),
            Log.message != ""
        )
        .group_by(Log.message)
        .order_by(func.count().desc())
        .limit(10)
    )

    # 4. –ü–æ–º–∏–ª–∫–∏ –ø–æ –∫—Ä–∞—ó–Ω–∞—Ö
    country_expr = cast(Log.custom["country"], String)
    country_query = (
        select(country_expr.label("country"), func.count().label("count"))
        .where(
            Log.token == project_token,
            # Log.level.in_(["error", "critical"]),
            country_expr.isnot(None),
            country_expr != ""
        )
        .group_by("country")
        .order_by(func.count().desc())
        .limit(5)
    )

    # –í–∏–∫–æ–Ω–∞–Ω–Ω—è –∑–∞–ø–∏—Ç—ñ–≤
    os_rows = (await db.execute(os_query)).all()
    model_rows = (await db.execute(model_query)).all()
    message_rows = (await db.execute(message_query)).all()
    country_rows = (await db.execute(country_query)).all()

    # –ü–æ–≤–µ—Ä–Ω–µ–Ω–Ω—è —É –≤—ñ–¥–ø–æ–≤—ñ–¥–Ω–æ–º—É —Ñ–æ—Ä–º–∞—Ç—ñ
    return FullAnalyticsOut(
        os_distribution=[
            OSStat(os=row.os, count=row.count) for row in os_rows
        ],
        top_devices=[
            DeviceStat(model=row.model, count=row.count) for row in model_rows
        ],
        top_messages=[
            MessageStat(message=row.message, count=row.count) for row in message_rows
        ],
        errors_by_country=[
            CountryStat(country=row.country, count=row.count) for row in country_rows
        ]
    )


